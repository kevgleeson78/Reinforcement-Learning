@misc{1introup63:online,
	author = {},
	title = {1 intro up to RL/TD.key},
	howpublished = {\url{https://login.cs.utexas.edu/sites/default/files/legacy_files/research/documents/1%20intro%20up%20to%20RL%3ATD.pdf}},
	month = {},
	year = {},
	note = {(Accessed on 03/28/2019)}
}

@book{123062420160101,
	Abstract = {About This BookBecome familiar with the most important and advanced parts of the Python code styleLearn the trickier aspects of Python and put it in a structured context for deeper understanding of the languageOffers an expert's-eye overview of how these advanced tasks fit together in Python as a whole along with practical examplesWho This Book Is ForAlmost anyone can learn to write working script and create high quality code but they might lack a structured understanding of what it means to be Pythonic. If you are a Python programmer who wants to code efficiently by getting the syntax and usage of a few intricate Python techniques exactly right, this book is for you.What You Will LearnLearn what it means to write Pythonic codeUse the functional programming paradigm effectively and how it relates to Lambda CalculusGet familiar with the different ways the decorators can be used and createdUnderstand the power of generators, coroutines, and asynchronous I/OCreate metaclasses and learn h},
	Author = {Hattem, Rick van},
	ISBN = {9781785289729},
	Publisher = {Packt Publishing},
	Series = {Community Experience Distilled},
	Title = {Mastering Python.},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=1230624&site=eds-live},
	Year = {2016},
}

@misc{Historya50:online,
	author = {},
	title = {History and License — Python 3.8.0a3 documentation},
	howpublished = {\url{https://docs.python.org/3.8/license.html}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}

@misc{PEP20The74:online,
	author = {},
	title = {PEP 20 -- The Zen of Python | Python.org},
	howpublished = {\url{https://www.python.org/dev/peps/pep-0020/}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}

@misc{Welcomet74:online,
	author = {},
	title = {Welcome to Python.org},
	howpublished = {\url{https://www.python.org/}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}

@misc{TryitEdi9:online,
	author = {},
	title = {Tryit Editor v3.6 - Show Python},
	howpublished = {\url{https://www.w3schools.com/python/showpython.asp?filename=demo_howto_reverse_string}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}

@misc{PythonDa73:online,
	author = {},
	title = {Python Data Analysis Library — pandas: Python Data Analysis Library},
	howpublished = {\url{https://pandas.pydata.org/}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}
@misc{Stateac29:online,
	author = {},
	title = {State–action–reward–state–action - Wikipedia},
	howpublished = {\url{https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}
@misc{Qlearnin52:online,
	author = {},
	title = {Q-learning - Wikipedia},
	howpublished = {\url{https://en.wikipedia.org/wiki/Q-learning}},
	month = {},
	year = {},
	note = {(Accessed on 04/11/2019)}
}
@misc{IntrotoD8:online,
	author = {},
	title = {Intro to Data Structures — pandas 0.24.2 documentation},
	howpublished = {\url{https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{Quicksta66:online,
	author = {},
	title = {Quickstart tutorial — NumPy v1.17.dev0 Manual},
	howpublished = {\url{https://www.numpy.org/devdocs/user/quickstart.html}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{GridWorl45:online,
	author = {},
	title = {Grid World (Part 3): Monte Carlo – Chris's Data Blog},
	howpublished = {\url{https://lachdata.com/2018/06/30/grid-world-part-3-monte-carlo/}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{Welcomet92:online,
	author = {},
	title = {Welcome to Flask — Flask 1.0.2 documentation},
	howpublished = {\url{http://flask.pocoo.org/docs/1.0/}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{Understa52:online,
	author = {},
	title = {Understanding rest},
	howpublished = {\url{https://spring.io/understanding/rest}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{JavaScri52:online,
	author = {},
	title = {JavaScript | MDN},
	howpublished = {\url{https://developer.mozilla.org/en-US/docs/Web/JavaScript}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{fontSize:online,
	author = {},
	title = {Tryit Editor v3.6},
	howpublished = {\url{https://www.w3schools.com/js/tryit.asp?filename=tryjs_intro_style}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{AJAX:online,
	author = {},
	title = {Getting Started - Developer guides | MDN},
	howpublished = {\url{https://developer.mozilla.org/en-US/docs/Web/Guide/AJAX/Getting_Started}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{AJAXDemo:online,
	author = {},
	title = {Tryit Editor v3.6},
	howpublished = {\url{https://www.w3schools.com/xml/tryit.asp?filename=tryajax_first}},
	month = {},
	year = {},
	note = {(Accessed on 04/12/2019)}
}
@misc{GoogleLineChart:online,
	author = {},
	title = {Line Chart  |  Charts  |  Google Developers},
	howpublished = {\url{https://developers.google.com/chart/interactive/docs/gallery/linechart}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{HeatMap:online,
	author = {},
	title = {GitHub - DLarsen/jquery-hottie: Simple Heatmap plugin},
	howpublished = {\url{https://github.com/DLarsen/jquery-hottie}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{HottieExample:online,
	author = {},
	title = {Edit fiddle - JSFiddle},
	howpublished = {\url{http://jsfiddle.net/larsenal/zVPka/}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{CanvasDoc:online,
	author = {},
	title = {Canvas API - Web APIs | MDN},
	howpublished = {\url{https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{CanvasExample:online,
	author = {},
	title = {HTML5 Canvas},
	howpublished = {\url{https://www.w3schools.com/html/html5_canvas.asp}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{Bootstrap:online,
	author = {},
	title = {Introduction · Bootstrap},
	howpublished = {\url{https://getbootstrap.com/docs/4.3/getting-started/introduction/}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{BootstrapGridExample:online,
	author = {},
	title = {Grid system · Bootstrap},
	howpublished = {\url{https://getbootstrap.com/docs/4.0/layout/grid/}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{JSON:online,
	author = {},
	title = {JSON},
	howpublished = {\url{https://www.json.org/}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{JSONstring:online,
	author = {},
	title = {JSON.stringify()},
	howpublished = {\url{https://www.w3schools.com/js/js_json_stringify.asp}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{CSVPython:online,
	author = {},
	title = {14.1. csv — CSV File Reading and Writing — Python 3.3.7 documentation},
	howpublished = {\url{https://docs.python.org/3.3/library/csv.html}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{ParsingCSVExample:online,
	author = {},
	title = {Parsing And Displaying CSV Files In jQuery - csv.js | Free jQuery Plugins},
	howpublished = {\url{https://www.jqueryscript.net/other/Parsing-Displaying-CSV-Files-jQuery.html}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{CreatingAppEngine:online,
	author = {},
	title = {Creating an App Engine Standard Application  |  Cloud Tools for Eclipse  |  Google Cloud},
	howpublished = {\url{https://cloud.google.com/eclipse/docs/creating-new-webapp}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@misc{FlaskAppGoolge:online,
	author = {},
	title = {Getting Started with Flask on App Engine Standard Environment  |  App Engine standard environment for Python  |  Google Cloud},
	howpublished = {\url{https://cloud.google.com/appengine/docs/standard/python/getting-started/python-standard-env}},
	month = {},
	year = {},
	note = {(Accessed on 04/15/2019)}
}
@book{sutton_barto_2018,
	edition={2},
	title={REINFORCEMENT LEARNING: an introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2015},
	publisher={MIT Press}
}
@misc{pandasProblem:online,
	author = {},
	title = {python - Using pandas .append within for loop - Stack Overflow},
	howpublished = {\url{https://stackoverflow.com/questions/37009287/using-pandas-append-within-for-loop}},
	month = {},
	year = {},
	note = {(Accessed on 04/24/2019)}
}
@misc{Udemy:online,
	author = {},
	title = {Artificial Intelligence: Reinforcement Learning in Python | Udemy},
	howpublished = {\url{https://www.udemy.com/course/artificial-intelligence-reinforcement-learning-in-python/}},
	month = {},
	year = {},
	note = {(Accessed on 04/25/2019)}
}
@article{nwana_1996, 
	title={Software agents: an overview}, 
	volume={11}, 
	DOI={10.1017/S026988890000789X}, 
	number={3}, 
	journal={The Knowledge Engineering Review}, 
	publisher={Cambridge University Press}, author={Nwana, Hyacinth S.}, year={1996}, 
	pages={205–244}}
@Article{Watkins1992,
	author="Watkins, Christopher J. C. H.
	and Dayan, Peter",
	title="Q-learning",
	journal="Machine Learning",
	year="1992",
	month="May",
	day="01",
	volume="8",
	number="3",
	pages="279--292",
	abstract="Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.",
	issn="1573-0565",
	doi="10.1007/BF00992698",
	url="https://doi.org/10.1007/BF00992698"
}
@incollection{LITTMAN1994157,
	title = "Markov games as a framework for multi-agent reinforcement learning",
	editor = "William W. Cohen and Haym Hirsh",
	booktitle = "Machine Learning Proceedings 1994",
	publisher = "Morgan Kaufmann",
	address = "San Francisco (CA)",
	pages = "157 - 163",
	year = "1994",
	isbn = "978-1-55860-335-6",
	doi = "https://doi.org/10.1016/B978-1-55860-335-6.50027-1",
	url = "http://www.sciencedirect.com/science/article/pii/B9781558603356500271",
	author = "Michael L. Littman",
	abstract = "In the Markov decision process (MDP) formalization of reinforcement learning, a single adaptive agent interacts with an environment defined by a probabilistic transition function. In this solipsis-tic view, secondary agents can only be part of the environment and are therefore fixed in their behavior. The framework of Markov games allows us to widen this view to include multiple adaptive agents with interacting or competing goals. This paper considers a step in this direction in which exactly two agents with diametrically opposed goals share an environment. It describes a Q-learning-like algorithm for finding optimal policies and demonstrates its application to a simple two-player game in which the optimal policy is probabilistic."
}
@Article{Lanzi2002,
	author="Lanzi, P. L.",
	title="Learning classifier systems from a reinforcement learning perspective",
	journal="Soft Computing",
	year="2002",
	month="Jun",
	day="01",
	volume="6",
	number="3",
	pages="162--170",
	abstract="{\enspace}We analyze learning classifier systems in the light of tabular reinforcement learning. We note that although genetic algorithms are the most distinctive feature of learning classifier systems, it is not clear whether genetic algorithms are important to learning classifiers systems. In fact, there are models which are strongly based on evolutionary computation (e.g., Wilson's XCS) and others which do not exploit evolutionary computation at all (e.g., Stolzmann's ACS). To find some clarifications, we try to develop learning classifier systems ``from scratch'', i.e., starting from one of the most known reinforcement learning technique, Q-learning. We first consider thebasics of reinforcement learning: a problem modeled as a Markov decision process and tabular Q-learning. We introduce a formal framework to define a general purpose rule-based representation which we use to implement tabular Q-learning. We formally define generalization within rules and discuss the possible approaches to extend our rule-based Q-learning with generalization capabilities. We suggest that genetic algorithms are probably the most general approach for adding generalization although they might be not the only solution.",
	issn="1432-7643",
	doi="10.1007/s005000100113",
	url="https://doi.org/10.1007/s005000100113"
}